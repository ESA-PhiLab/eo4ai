{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to get small test samples that can be used to test Dataset classes. Tests should then be written that check metadata values, file structure, normalisation, splitting locations etc. of each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import tifffile as tif\n",
    "import glymur\n",
    "import cv2\n",
    "import spectral as spy\n",
    "import skimage.io\n",
    "\n",
    "import pprint\n",
    "\n",
    "np.random.seed(1123)\n",
    "random.seed(259)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths for root directories of datasets\n",
    "\n",
    "L7Irish206_dir = 'E:/datasets/L7Irish206'\n",
    "L8Biome96_dir = 'E:/datasets/L8Biome96'\n",
    "L8SPARCS80_dir = 'D:/datasets/clouds/L8SPARCS80'\n",
    "S2CESBIO38_dir = 'E:/datasets/S2CESBIO38'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L7Irish206 SCENE:  E:/datasets/L7Irish206\\p108_r18\n",
      "L8Biome96 SCENE:  E:/datasets/L8Biome96\\Urban\\LC81940222013245LGN00\n",
      "L8SPARCS80 SCENE:  D:/datasets/clouds/L8SPARCS80\\LC80340412013132LGN01\n",
      "S2CESBIO38 SCENE:  E:/datasets/S2CESBIO38\\Reference_dataset\\scene_20\\Classification\n"
     ]
    }
   ],
   "source": [
    "# Randomly select a scene for each dataset.\n",
    "\n",
    "## L7Irish206\n",
    "scene_dirs = []\n",
    "for root,dirs,paths in os.walk(L7Irish206_dir):\n",
    "    for path in paths:\n",
    "        if 'mask2019' in path:\n",
    "            scene_dirs.append(root)\n",
    "L7Irish206_sceneid = random.choice(scene_dirs)\n",
    "print('L7Irish206 SCENE: ',L7Irish206_sceneid)\n",
    "\n",
    "\n",
    "## L8Biome96\n",
    "scene_dirs = []\n",
    "for root,dirs,paths in os.walk(L8Biome96_dir):\n",
    "    for path in paths:\n",
    "        if 'fixedmask.hdr' in path:\n",
    "            scene_dirs.append(root)\n",
    "L8Biome96_sceneid = random.choice(scene_dirs)            \n",
    "print('L8Biome96 SCENE: ',L8Biome96_sceneid)\n",
    "\n",
    "\n",
    "## L8SPARCS80\n",
    "scenes = [\n",
    "          os.path.join(L8SPARCS80_dir,path)[:-12] \n",
    "          for path in os.listdir(L8SPARCS80_dir) \n",
    "          if path.endswith('_mask.png')\n",
    "         ]\n",
    "L8SPARCS80_sceneid = random.choice(scenes) \n",
    "print('L8SPARCS80 SCENE: ',L8SPARCS80_sceneid)\n",
    "\n",
    "\n",
    "## S2CESBIO38\n",
    "scene_dirs = []\n",
    "for root,dirs,paths in os.walk(S2CESBIO38_dir):\n",
    "    for path in paths:\n",
    "        if 'classification_map' in path:\n",
    "            scene_dirs.append(root)\n",
    "S2CESBIO38_sceneid = random.choice(scene_dirs)   \n",
    "print('S2CESBIO38 SCENE: ',S2CESBIO38_sceneid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 0.5000655222120298, 0.5000655222120298, 1.0, 1.9998689555759404]\n",
      "(952, 820, 9)\n",
      "(952, 820)\n"
     ]
    }
   ],
   "source": [
    "# Extract an image/mask for L7Irish206.\n",
    "\n",
    "\n",
    "L7Irish206_band_ids = ['B10.TIF',\n",
    "                       'B20.TIF',\n",
    "                       'B30.TIF',\n",
    "                       'B40.TIF',\n",
    "                       'B50.TIF',\n",
    "                       'B61.TIF',\n",
    "                       'B62.TIF',\n",
    "                       'B70.TIF',\n",
    "                       'B80.TIF']\n",
    "L7Irish206_bands = []\n",
    "for band_id in L7Irish206_band_ids:\n",
    "    for root,dirs,paths in os.walk(L7Irish206_sceneid):\n",
    "        for path in paths:\n",
    "            if band_id in path:\n",
    "                L7Irish206_bands.append(tif.imread(os.path.join(root,path)).astype('float64'))\n",
    "    \n",
    "for root,dirs,paths in os.walk(L7Irish206_sceneid):\n",
    "    for path in paths:\n",
    "        if 'mask2019' in path:\n",
    "            L7Irish206_mask = tif.imread(os.path.join(root,path))\n",
    "L7Irish206_scale_factors = [band.shape[0]/L7Irish206_bands[0].shape[0] for band in L7Irish206_bands]\n",
    "print(L7Irish206_scale_factors)\n",
    "L7Irish206_bands = np.stack([cv2.resize(band,L7Irish206_bands[0].shape[::-1],cv2.INTER_NEAREST) for band in L7Irish206_bands], axis=-1)\n",
    "\n",
    "# GET REGION FOR CROP\n",
    "centre = [int(L7Irish206_bands.shape[0]/2),int(L7Irish206_bands.shape[1]/2)]\n",
    "patch_size = [random.randint(700,1000),random.randint(700,1000)]\n",
    "top_left = [random.randint(centre[0]-patch_size[0],centre[0]),random.randint(centre[1]-patch_size[1],centre[1])]\n",
    "crop = slice(top_left[0],top_left[0]+patch_size[0]),slice(top_left[1],top_left[1]+patch_size[1])\n",
    "\n",
    "L7Irish206_bands = L7Irish206_bands[crop]\n",
    "L7Irish206_mask = L7Irish206_mask[crop]\n",
    "\n",
    "print(L7Irish206_bands.shape)\n",
    "print(L7Irish206_mask.shape)\n",
    "\n",
    "# Now we separate the input data from the desired output and save it as our synthetic dataset\n",
    "\n",
    "L7Irish206_bands_list = [L7Irish206_bands[...,i] for i in range(L7Irish206_bands.shape[-1])]\n",
    "L7Irish206_input_bands=[]\n",
    "for band,s_f in zip(L7Irish206_bands_list,L7Irish206_scale_factors):\n",
    "    L7Irish206_input_bands.append(cv2.resize(band,tuple(int(d*s_f) for d in band.shape[::-1]),cv2.INTER_NEAREST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alist\\Anaconda3\\envs\\TF2\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.9998786555029728, 1.0, 1.0, 1.0]\n",
      "(724, 964, 11)\n",
      "(724, 964)\n"
     ]
    }
   ],
   "source": [
    "# Extract an image/mask for L8Biome96.\n",
    "\n",
    "\n",
    "L8Biome96_band_ids = ['B1.TIF','B2.TIF','B3.TIF','B4.TIF','B5.TIF','B6.TIF','B7.TIF','B8.TIF','B9.TIF','B10.TIF','B11.TIF']\n",
    "L8Biome96_bands = []\n",
    "for band_id in L8Biome96_band_ids:\n",
    "    for root,dirs,paths in os.walk(L8Biome96_sceneid):\n",
    "        for path in paths:\n",
    "            if band_id in path:\n",
    "                L8Biome96_bands.append(tif.imread(os.path.join(root,path)).astype('float64'))\n",
    "    \n",
    "for root,dirs,paths in os.walk(L8Biome96_sceneid):\n",
    "    for path in paths:\n",
    "        if '_fixedmask.hdr' in path:\n",
    "            L8Biome96_mask = np.squeeze(spy.open_image(os.path.join(root,path)).load())\n",
    "            \n",
    "L8Biome96_scale_factors = [band.shape[0]/L8Biome96_bands[0].shape[0] for band in L8Biome96_bands]\n",
    "print(L8Biome96_scale_factors)\n",
    "L8Biome96_bands = np.stack([cv2.resize(band,L8Biome96_bands[0].shape[::-1],cv2.INTER_NEAREST) for band in L8Biome96_bands], axis=-1)\n",
    "\n",
    "# GET REGION FOR CROP\n",
    "centre = [int(L8Biome96_bands.shape[0]/2),int(L8Biome96_bands.shape[1]/2)]\n",
    "patch_size = [random.randint(700,1000),random.randint(700,1000)]\n",
    "top_left = [random.randint(centre[0]-patch_size[0],centre[0]),random.randint(centre[1]-patch_size[1],centre[1])]\n",
    "crop = slice(top_left[0],top_left[0]+patch_size[0]),slice(top_left[1],top_left[1]+patch_size[1])\n",
    "\n",
    "L8Biome96_bands = L8Biome96_bands[crop]\n",
    "L8Biome96_mask = L8Biome96_mask[crop]\n",
    "\n",
    "print(L8Biome96_bands.shape)\n",
    "print(L8Biome96_mask.shape)\n",
    "\n",
    "# Now we separate the input data from the desired output and save it as our synthetic dataset\n",
    "\n",
    "L8Biome96_bands_list = [L8Biome96_bands[...,i] for i in range(L8Biome96_bands.shape[-1])]\n",
    "L8Biome96_input_bands=[]\n",
    "for band,s_f in zip(L8Biome96_bands_list,L8Biome96_scale_factors):\n",
    "    L8Biome96_input_bands.append(cv2.resize(band,tuple(int(d*s_f) for d in band.shape[::-1]),cv2.INTER_NEAREST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(321, 350, 10)\n",
      "(321, 350, 3)\n"
     ]
    }
   ],
   "source": [
    "# Extract an image/mask for L8SPARCS80.\n",
    "\n",
    "\n",
    "L8SPARCS80_band_ids = ['B1','B2','B3','B4','B5','B6','B7','B9','B10','B11']\n",
    "for path in os.listdir(L8SPARCS80_dir):\n",
    "    if os.path.split(L8SPARCS80_sceneid)[1] in path and '_data' in path:\n",
    "        L8SPARCS80_bands = tif.imread(os.path.join(L8SPARCS80_dir,path)).astype('float64')\n",
    "    elif os.path.split(L8SPARCS80_sceneid)[1] in path and '_mask' in path:\n",
    "        L8SPARCS80_mask = skimage.io.imread(os.path.join(L8SPARCS80_dir,path))\n",
    "\n",
    "      \n",
    "# GET REGION FOR CROP\n",
    "centre = [int(L8SPARCS80_bands.shape[0]/2),int(L8SPARCS80_bands.shape[1]/2)]\n",
    "patch_size = [random.randint(300,460),random.randint(300,460)]\n",
    "top_left = [random.randint(centre[0]-patch_size[0],centre[0]),random.randint(centre[1]-patch_size[1],centre[1])]\n",
    "crop = slice(top_left[0],top_left[0]+patch_size[0]),slice(top_left[1],top_left[1]+patch_size[1])\n",
    "\n",
    "L8SPARCS80_bands = L8SPARCS80_bands[crop]\n",
    "L8SPARCS80_mask = L8SPARCS80_mask[crop]\n",
    "\n",
    "print(L8SPARCS80_bands.shape)\n",
    "print(L8SPARCS80_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 6.0, 6.0, 6.0, 3.0, 3.0, 3.0, 6.0, 3.0, 1.0, 1.0, 3.0, 3.0]\n",
      "(335, 334, 13)\n",
      "(335, 334)\n"
     ]
    }
   ],
   "source": [
    "# Extract an image/mask for S2CESBIO.\n",
    "\n",
    "\n",
    "S2CESBIO38_band_ids = ['B01.jp2',\n",
    "                      'B02.jp2',\n",
    "                      'B03.jp2',\n",
    "                      'B04.jp2',\n",
    "                      'B05.jp2',\n",
    "                      'B06.jp2',\n",
    "                      'B07.jp2',\n",
    "                      'B08.jp2',\n",
    "                      'B8A.jp2',\n",
    "                      'B09.jp2',\n",
    "                      'B10.jp2',\n",
    "                      'B11.jp2',\n",
    "                      'B12.jp2'\n",
    "                      ]\n",
    "S2CESBIO38_bands = []\n",
    "for band_id in S2CESBIO38_band_ids:\n",
    "    for root,dirs,paths in os.walk(S2CESBIO38_sceneid):\n",
    "        for path in paths:\n",
    "            if band_id in path:\n",
    "                S2CESBIO38_bands.append(glymur.Jp2k(os.path.join(root,path))[:].astype('float64'))\n",
    "    \n",
    "for root,dirs,paths in os.walk(S2CESBIO38_sceneid):\n",
    "    for path in paths:\n",
    "        if 'classification_map' in path:\n",
    "            S2CESBIO38_mask = tif.imread(os.path.join(root,path))\n",
    "            \n",
    "# Resize all bands to same resolution as first band and make into array\n",
    "S2CESBIO38_scale_factors = [band.shape[0]/S2CESBIO38_bands[0].shape[0] for band in S2CESBIO38_bands]\n",
    "print(S2CESBIO38_scale_factors)\n",
    "S2CESBIO38_bands = np.stack([cv2.resize(band,S2CESBIO38_bands[0].shape[::-1],cv2.INTER_NEAREST) for band in S2CESBIO38_bands], axis=-1)\n",
    "\n",
    "\n",
    "# GET REGION FOR CROP\n",
    "centre = [int(S2CESBIO38_bands.shape[0]/2),int(S2CESBIO38_bands.shape[1]/2)]\n",
    "patch_size = [random.randint(300,500),random.randint(300,500)]\n",
    "top_left = [random.randint(centre[0]-patch_size[0],centre[0]),random.randint(centre[1]-patch_size[1],centre[1])]\n",
    "crop = slice(top_left[0],top_left[0]+patch_size[0]),slice(top_left[1],top_left[1]+patch_size[1])\n",
    "\n",
    "S2CESBIO38_bands = S2CESBIO38_bands[crop]\n",
    "S2CESBIO38_mask = S2CESBIO38_mask[crop]\n",
    "\n",
    "print(S2CESBIO38_bands.shape)\n",
    "print(S2CESBIO38_mask.shape)\n",
    "\n",
    "# Now we separate the input data from the desired output and save it as our synthetic dataset\n",
    "\n",
    "S2CESBIO38_bands_list = [S2CESBIO38_bands[...,i] for i in range(S2CESBIO38_bands.shape[-1])]\n",
    "S2CESBIO38_input_bands=[]\n",
    "for band,s_f in zip(S2CESBIO38_bands_list,S2CESBIO38_scale_factors):\n",
    "    S2CESBIO38_input_bands.append(cv2.resize(band,tuple(int(d*s_f) for d in band.shape[::-1]),cv2.INTER_NEAREST))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(335, 334)\n",
      "(2010, 2004)\n",
      "(2010, 2004)\n",
      "(2010, 2004)\n",
      "(1005, 1002)\n",
      "(1005, 1002)\n",
      "(1005, 1002)\n",
      "(2010, 2004)\n",
      "(1005, 1002)\n",
      "(335, 334)\n",
      "(335, 334)\n",
      "(1005, 1002)\n",
      "(1005, 1002)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 150)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
